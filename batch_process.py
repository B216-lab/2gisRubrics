# batch_process.py
"""
Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² CSV
"""

import os
import glob
from pathlib import Path
from data_processor import DataProcessor
from classifier import CompanyClassifier
import json
from datetime import datetime

def process_all_csv_files(input_dir='data', output_dir='output'):
    """
    ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ²ÑĞµ CSV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ² Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
    
    Args:
        input_dir: Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼Ğ¸
        output_dir: Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
    """
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
    Path(output_dir).mkdir(exist_ok=True)
    
    # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ²ÑĞµ CSV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ² input_dir (ĞºÑ€Ğ¾Ğ¼Ğµ categories.csv)
    csv_files = glob.glob(f"{input_dir}/**/*.csv", recursive=True)
    csv_files = [f for f in csv_files if 'categories' not in f and 'training' not in f]
    
    if not csv_files:
        print(f"âœ— CSV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ² {input_dir}")
        return
    
    print(f"ğŸ“‚ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(csv_files)} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸\n")
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
    processor = DataProcessor()
    all_results = []
    
    for file_path in csv_files:
        filename = Path(file_path).name
        print(f"ğŸ”„ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°: {filename}")
        
        try:
            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼
            processor.load_companies(file_path)
            
            # ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµĞ¼
            processor.classify_companies()
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
            output_file = f"{output_dir}/classified_{filename}"
            processor.save_classified(output_file)
            
            # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚
            report_file = f"{output_dir}/report_{filename.replace('.csv', '.json')}"
            report = processor.generate_report(report_file)
            
            all_results.append({
                'file': filename,
                'status': 'success',
                'total_companies': len(processor.classified_df),
                'avg_confidence': float(report['avg_confidence']),
                'categories': len(report['categories_distribution']),
                'output_file': output_file
            })
            
            print(f"âœ“ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾: {output_file}\n")
            
        except Exception as e:
            print(f"âœ— ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ {filename}: {e}\n")
            all_results.append({
                'file': filename,
                'status': 'error',
                'error': str(e)
            })
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚
    summary = {
        'timestamp': datetime.now().isoformat(),
        'files_processed': len([r for r in all_results if r['status'] == 'success']),
        'files_failed': len([r for r in all_results if r['status'] == 'error']),
        'results': all_results
    }
    
    summary_file = f"{output_dir}/batch_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*70}")
    print(f"âœ“ ĞŸĞ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°")
    print(f"  Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾: {summary['files_processed']}")
    print(f"  ĞÑˆĞ¸Ğ±Ğ¾Ğº: {summary['files_failed']}")
    print(f"  Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚: {summary_file}")
    print(f"{'='*70}")
    
    return summary

def apply_training_rules(rules_file='data/training_rules.json'):
    """
    ĞŸÑ€Ğ¸Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°
    """
    classifier = CompanyClassifier()
    
    if not Path(rules_file).exists():
        print(f"âœ— Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {rules_file}")
        return
    
    with open(rules_file, 'r', encoding='utf-8') as f:
        rules_data = json.load(f)
    
    rules = rules_data.get('rules', [])
    print(f"ğŸ“š ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ {len(rules)} Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ...\n")
    
    for rule in rules:
        print(f"  â†’ '{rule['keyword']}' â†’ {rule['category']} (Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚: {rule['priority']})")
    
    print(f"\nâœ“ Ğ’ÑĞµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹")
    return classifier

if __name__ == '__main__':
    import sys
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         ĞŸĞ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Classification System           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    if len(sys.argv) > 1:
        input_dir = sys.argv[1]
        output_dir = sys.argv[2] if len(sys.argv) > 2 else 'output'
    else:
        input_dir = 'data'
        output_dir = 'output'
    
    process_all_csv_files(input_dir, output_dir)
