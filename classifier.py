# classifier_–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô_V2.py
"""
–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞: training_rules - —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –Ω–µ —Å–ª–æ–≤–∞—Ä—å
‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
"""

import pickle
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
import os
from pathlib import Path

class CompanyClassifier:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–æ–º–ø–∞–Ω–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–∞–≤–∏–ª"""
    
    def __init__(self, model_path='models'):
        self.model_path = Path(model_path)
        self.model_path.mkdir(exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.vectorizer = None
        self.classifier = None
        self.label_encoder = None
        self.training_rules = []  # –ò–°–ü–†–ê–í–õ–ï–ù–û: —ç—Ç–æ —Å–ø–∏—Å–æ–∫!
        self.categories = []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self.load_model()
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ —Ñ–∞–π–ª–æ–≤"""
        try:
            vectorizer_path = self.model_path / 'vectorizer.pkl'
            classifier_path = self.model_path / 'classifier_model.pkl'
            encoder_path = self.model_path / 'label_encoder.pkl'
            
            if vectorizer_path.exists():
                with open(vectorizer_path, 'rb') as f:
                    self.vectorizer = pickle.load(f)
            
            if classifier_path.exists():
                with open(classifier_path, 'rb') as f:
                    self.classifier = pickle.load(f)
            
            if encoder_path.exists():
                with open(encoder_path, 'rb') as f:
                    self.label_encoder = pickle.load(f)
            
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª–µ–π –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ
            if not self.vectorizer:
                self.vectorizer = TfidfVectorizer(max_features=5000, lowercase=True, stop_words='english')
            
            if not self.classifier:
                self.classifier = MultinomialNB()
            
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.vectorizer = TfidfVectorizer(max_features=5000, lowercase=True, stop_words='english')
            self.classifier = MultinomialNB()
    
    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –≤ —Ñ–∞–π–ª—ã"""
        try:
            if self.vectorizer:
                with open(self.model_path / 'vectorizer.pkl', 'wb') as f:
                    pickle.dump(self.vectorizer, f)
            
            if self.classifier:
                with open(self.model_path / 'classifier_model.pkl', 'wb') as f:
                    pickle.dump(self.classifier, f)
            
            if self.label_encoder:
                with open(self.model_path / 'label_encoder.pkl', 'wb') as f:
                    pickle.dump(self.label_encoder, f)
            
            print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    def add_training_rule(self, keyword, category, priority=50):
        """–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –¥–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç –≤ —Å–ø–∏—Å–æ–∫, –Ω–µ –≤ —Å–ª–æ–≤–∞—Ä—å
            rule = {
                'keyword': keyword.lower(),
                'category': category,
                'priority': priority
            }
            self.training_rules.append(rule)
            print(f"‚úÖ –ü—Ä–∞–≤–∏–ª–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {keyword} -> {category}")
            return True
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª–∞: {e}")
            return False
    
    def check_rules(self, text):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—Å—Ç –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º"""
        try:
            text_lower = text.lower()
            matched_rules = []
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: iterate –ø–æ —Å–ø–∏—Å–∫—É –ø—Ä–∞–≤–∏–ª
            for rule in self.training_rules:
                keyword = rule.get('keyword', '')
                category = rule.get('category', '')
                priority = rule.get('priority', 50)
                
                if keyword and keyword in text_lower:
                    matched_rules.append({
                        'category': category,
                        'priority': priority,
                        'keyword': keyword
                    })
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–∞–≤–∏–ª–æ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
            if matched_rules:
                best_rule = max(matched_rules, key=lambda x: x['priority'])
                return best_rule['category'], best_rule['priority'] / 100.0
            
            return None, None
        
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∞–≤–∏–ª: {e}")
            return None, None
    
    def classify_text(self, text):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç"""
        try:
            if not text or not isinstance(text, str):
                return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª–∞
            rule_category, rule_confidence = self.check_rules(text)
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø—Ä–∞–≤–∏–ª–æ —Å –≤—ã—Å–æ–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if rule_category and rule_confidence and rule_confidence > 0.7:
                return rule_category, rule_confidence
            
            # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å
            if not self.classifier or not self.vectorizer:
                return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0
            
            try:
                # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
                X = self.vectorizer.transform([text])
                
                # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                probabilities = self.classifier.predict_proba(X)[0]
                
                # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å—ã
                classes = self.classifier.classes_
                
                # –ù–∞—Ö–æ–¥–∏–º –∫–ª–∞—Å—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
                max_idx = np.argmax(probabilities)
                predicted_class = classes[max_idx]
                predicted_prob = probabilities[max_idx]
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                category = str(predicted_class) if predicted_class else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
                confidence = float(predicted_prob) if predicted_prob else 0.0
                
                return category, confidence
            
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–¥–µ–ª—å—é: {e}")
                return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ classify_text: {e}")
            return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0
    
    def classify_top_n(self, text, n=3):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –≤–µ—Ä–Ω—É—Ç—å —Ç–æ–ø N"""
        try:
            if not text or not isinstance(text, str):
                return [('–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0)]
            
            if not self.classifier or not self.vectorizer:
                return [('–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0)]
            
            try:
                # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
                X = self.vectorizer.transform([text])
                
                # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                probabilities = self.classifier.predict_proba(X)[0]
                
                # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Å—ã
                classes = self.classifier.classes_
                
                # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ (–∫–ª–∞—Å—Å, –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
                results = []
                for cls, prob in zip(classes, probabilities):
                    results.append((str(cls), float(prob)))
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ —É–±—ã–≤–∞—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ
                results.sort(key=lambda x: x[1], reverse=True)
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø N
                return results[:n] if results else [('–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0)]
            
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ classify_top_n: {e}")
                return [('–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0)]
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ classify_top_n: {e}")
            return [('–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0.0)]
    
    def train(self, texts, labels):
        """–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"""
        try:
            if not texts or not labels:
                print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return False
            
            # –û–±—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä
            X = self.vectorizer.fit_transform(texts)
            
            # –û–±—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
            self.classifier.fit(X, labels)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            self.categories = list(set(labels))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            self.save_model()
            
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ {len(texts)} –ø—Ä–∏–º–µ—Ä–∞—Ö")
            return True
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False


# ==================== –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø ====================

class TextClassifier:
    """–ì–ª–∞–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
    
    def __init__(self):
        self.classifier = CompanyClassifier()
    
    def classify_text(self, text):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç"""
        return self.classifier.classify_text(text)
    
    def classify_top_n(self, text, n=3):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –≤–µ—Ä–Ω—É—Ç—å —Ç–æ–ø N"""
        return self.classifier.classify_top_n(text, n=n)
    
    def add_training_rule(self, keyword, category, priority=50):
        """–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∞–≤–∏–ª–æ"""
        return self.classifier.add_training_rule(keyword, category, priority)


# ==================== –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï ====================

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ V2...")
    
    classifier = CompanyClassifier()
    
    # –ü—Ä–∏–º–µ—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    test_text = "IT –∫–æ–º–ø–∞–Ω–∏—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è"
    category, confidence = classifier.classify_text(test_text)
    print(f"\n–¢–µ–∫—Å—Ç: {test_text}")
    print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")
    print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence*100:.1f}%")
    
    # –ü—Ä–∏–º–µ—Ä –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª–∞
    classifier.add_training_rule('IT', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', priority=80)
    
    # –ü—Ä–∏–º–µ—Ä —Ç–æ–ø-3
    top_3 = classifier.classify_top_n(test_text, n=3)
    print(f"\n–¢–æ–ø-3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:")
    for cat, conf in top_3:
        print(f"  - {cat}: {conf*100:.1f}%")
    
    print("\n‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
